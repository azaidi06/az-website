{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis Abstract Web Scraper\n",
    "\n",
    "This notebook allows you to scrape recent tennis match data from Tennis Abstract for Top 25 ATP and WTA players.\n",
    "\n",
    "**Data Source**: [Tennis Abstract](https://www.tennisabstract.com/)  \n",
    "**Base Data**: [Jeff Sackmann's tennis_atp/tennis_wta repos](https://github.com/JeffSackmann/tennis_atp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Options\n",
    "# =====================\n",
    "\n",
    "# Which tour to scrape: \"atp\", \"wta\", or \"both\"\n",
    "TOUR = \"both\"\n",
    "\n",
    "# Minimum year to scrape (matches before this year are skipped)\n",
    "MIN_YEAR = 2025\n",
    "\n",
    "# Maximum number of players to scrape per tour (None = all 25)\n",
    "# Use a small number (e.g., 3) for testing\n",
    "MAX_PLAYERS = None\n",
    "\n",
    "# Whether to merge scraped data with existing data\n",
    "MERGE_WITH_EXISTING = True\n",
    "\n",
    "# Rate limiting (seconds between requests)\n",
    "RATE_LIMIT_SECONDS = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_missing(package, import_name=None):\n",
    "    import_name = import_name or package\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        print(f\"✓ {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "        print(f\"✓ {package} installed\")\n",
    "\n",
    "install_if_missing(\"playwright\")\n",
    "install_if_missing(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Playwright browser (run once)\n",
    "import os\n",
    "if not os.path.exists(os.path.expanduser(\"~/.cache/ms-playwright/chromium_headless_shell-1208\")):\n",
    "    print(\"Installing Chromium browser for Playwright...\")\n",
    "    !playwright install chromium\n",
    "else:\n",
    "    print(\"✓ Chromium browser already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeout\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Player Lists\n",
    "\n",
    "Top 25 players for each tour with their Tennis Abstract URL names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 25 ATP Players (player_id, url_name, full_name)\n",
    "ATP_TOP_25 = [\n",
    "    (206173, \"JannikSinner\", \"Jannik Sinner\"),\n",
    "    (100644, \"AlexanderZverev\", \"Alexander Zverev\"),\n",
    "    (207989, \"CarlosAlcaraz\", \"Carlos Alcaraz\"),\n",
    "    (126203, \"TaylorFritz\", \"Taylor Fritz\"),\n",
    "    (106421, \"DaniilMedvedev\", \"Daniil Medvedev\"),\n",
    "    (134770, \"AlexDeMinaur\", \"Alex de Minaur\"),\n",
    "    (104925, \"NovakDjokovic\", \"Novak Djokovic\"),\n",
    "    (126094, \"CasperRuud\", \"Casper Ruud\"),\n",
    "    (200282, \"AndreyRublev\", \"Andrey Rublev\"),\n",
    "    (105777, \"GrigorDimitrov\", \"Grigor Dimitrov\"),\n",
    "    (126774, \"TommyPaul\", \"Tommy Paul\"),\n",
    "    (126205, \"FrancesTiafoe\", \"Frances Tiafoe\"),\n",
    "    (208029, \"HolgerRune\", \"Holger Rune\"),\n",
    "    (200005, \"LorenzoMusetti\", \"Lorenzo Musetti\"),\n",
    "    (207733, \"UgoHumbert\", \"Ugo Humbert\"),\n",
    "    (128034, \"JackDraper\", \"Jack Draper\"),\n",
    "    (207518, \"ArthurFils\", \"Arthur Fils\"),\n",
    "    (126207, \"SebastianKorda\", \"Sebastian Korda\"),\n",
    "    (111575, \"KarenKhachanov\", \"Karen Khachanov\"),\n",
    "    (209950, \"AlexMichelsen\", \"Alex Michelsen\"),\n",
    "    (210097, \"GiovanniMpetshiPerricard\", \"Giovanni Mpetshi Perricard\"),\n",
    "    (200624, \"AdrianMannarino\", \"Adrian Mannarino\"),\n",
    "    (126214, \"BenShelton\", \"Ben Shelton\"),\n",
    "    (200615, \"FelixAugerAliassime\", \"Felix Auger-Aliassime\"),\n",
    "    (207830, \"TaroDaniel\", \"Taro Daniel\"),\n",
    "]\n",
    "\n",
    "# Top 25 WTA Players (player_id, url_name, full_name)\n",
    "WTA_TOP_25 = [\n",
    "    (214544, \"ArynaSabalenka\", \"Aryna Sabalenka\"),\n",
    "    (216347, \"IgaSwiatek\", \"Iga Swiatek\"),\n",
    "    (221103, \"CocoGauff\", \"Coco Gauff\"),\n",
    "    (211148, \"JasminePaolini\", \"Jasmine Paolini\"),\n",
    "    (221012, \"QinwenZheng\", \"Qinwen Zheng\"),\n",
    "    (214981, \"JessicaPegula\", \"Jessica Pegula\"),\n",
    "    (202468, \"ElenaRybakina\", \"Elena Rybakina\"),\n",
    "    (215613, \"EmmaNavarro\", \"Emma Navarro\"),\n",
    "    (214082, \"DariaKasatkina\", \"Daria Kasatkina\"),\n",
    "    (206252, \"BeatrizHaddadMaia\", \"Beatriz Haddad Maia\"),\n",
    "    (203389, \"DanielleCollins\", \"Danielle Collins\"),\n",
    "    (211651, \"MirraAndreeva\", \"Mirra Andreeva\"),\n",
    "    (223670, \"DianaShnaider\", \"Diana Shnaider\"),\n",
    "    (214939, \"AnnaKalinskaya\", \"Anna Kalinskaya\"),\n",
    "    (211533, \"DonnaVekic\", \"Donna Vekic\"),\n",
    "    (259799, \"MadisonKeys\", \"Madison Keys\"),\n",
    "    (206242, \"PaulaBadosa\", \"Paula Badosa\"),\n",
    "    (216146, \"LinaTsurenko\", \"Lina Tsurenko\"),\n",
    "    (202499, \"LindaNoskova\", \"Linda Noskova\"),\n",
    "    (201458, \"MarieBouzkova\", \"Marie Bouzkova\"),\n",
    "    (201619, \"KarolinaPliskova\", \"Karolina Pliskova\"),\n",
    "    (214096, \"AnastasiaPavlyuchenkova\", \"Anastasia Pavlyuchenkova\"),\n",
    "    (202494, \"ElinaSvitolina\", \"Elina Svitolina\"),\n",
    "    (211107, \"VeronikaKudermetova\", \"Veronika Kudermetova\"),\n",
    "    (211684, \"LeylaFernandez\", \"Leyla Fernandez\"),\n",
    "]\n",
    "\n",
    "print(f\"ATP Players: {len(ATP_TOP_25)}\")\n",
    "print(f\"WTA Players: {len(WTA_TOP_25)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scraper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory setup\n",
    "DATA_DIR = Path(\".\")\n",
    "OUTPUT_DIR = DATA_DIR / \"top25\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "(OUTPUT_DIR / \"atp\").mkdir(exist_ok=True)\n",
    "(OUTPUT_DIR / \"wta\").mkdir(exist_ok=True)\n",
    "\n",
    "def get_match_columns():\n",
    "    \"\"\"Return column names matching Sackmann's format.\"\"\"\n",
    "    return [\n",
    "        \"tourney_id\", \"tourney_name\", \"surface\", \"draw_size\", \"tourney_level\",\n",
    "        \"tourney_date\", \"match_num\", \"winner_id\", \"winner_seed\", \"winner_entry\",\n",
    "        \"winner_name\", \"winner_hand\", \"winner_ht\", \"winner_ioc\", \"winner_age\",\n",
    "        \"loser_id\", \"loser_seed\", \"loser_entry\", \"loser_name\", \"loser_hand\",\n",
    "        \"loser_ht\", \"loser_ioc\", \"loser_age\", \"score\", \"best_of\", \"round\",\n",
    "        \"minutes\", \"w_ace\", \"w_df\", \"w_svpt\", \"w_1stIn\", \"w_1stWon\", \"w_2ndWon\",\n",
    "        \"w_SvGms\", \"w_bpSaved\", \"w_bpFaced\", \"l_ace\", \"l_df\", \"l_svpt\", \"l_1stIn\",\n",
    "        \"l_1stWon\", \"l_2ndWon\", \"l_SvGms\", \"l_bpSaved\", \"l_bpFaced\", \"winner_rank\",\n",
    "        \"winner_rank_points\", \"loser_rank\", \"loser_rank_points\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_round(round_str):\n",
    "    \"\"\"Convert Tennis Abstract round format to Sackmann format.\"\"\"\n",
    "    round_map = {\n",
    "        \"F\": \"F\", \"SF\": \"SF\", \"QF\": \"QF\", \"R16\": \"R16\",\n",
    "        \"R32\": \"R32\", \"R64\": \"R64\", \"R128\": \"R128\", \"RR\": \"RR\", \"BR\": \"BR\",\n",
    "        \"1R\": \"R128\", \"2R\": \"R64\", \"3R\": \"R32\", \"4R\": \"R16\",\n",
    "    }\n",
    "    return round_map.get(round_str.strip(), round_str)\n",
    "\n",
    "def parse_surface(surface_str):\n",
    "    \"\"\"Normalize surface names.\"\"\"\n",
    "    surface_str = surface_str.lower().strip()\n",
    "    if \"hard\" in surface_str: return \"Hard\"\n",
    "    elif \"clay\" in surface_str: return \"Clay\"\n",
    "    elif \"grass\" in surface_str: return \"Grass\"\n",
    "    elif \"carpet\" in surface_str: return \"Carpet\"\n",
    "    return surface_str.title()\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Parse date string and return (YYYYMMDD format, year).\"\"\"\n",
    "    formats = [\"%d-%b-%Y\", \"%Y-%m-%d\", \"%d %b %Y\", \"%b %d, %Y\", \"%Y/%m/%d\"]\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            dt = datetime.strptime(date_str.strip(), fmt)\n",
    "            return dt.strftime(\"%Y%m%d\"), dt.year\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return \"\", 0\n",
    "\n",
    "def parse_time_to_minutes(time_str):\n",
    "    \"\"\"Convert time string like '2:23' to minutes.\"\"\"\n",
    "    try:\n",
    "        parts = time_str.strip().split(':')\n",
    "        if len(parts) == 2:\n",
    "            return str(int(parts[0]) * 60 + int(parts[1]))\n",
    "    except (ValueError, IndexError):\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "def parse_result_cell(result_text, player_name):\n",
    "    \"\"\"Parse result cell to extract winner/loser info.\"\"\"\n",
    "    if \" d. \" not in result_text:\n",
    "        return False, \"\", \"\", \"\", \"\"\n",
    "    \n",
    "    parts = result_text.split(\" d. \")\n",
    "    if len(parts) != 2:\n",
    "        return False, \"\", \"\", \"\", \"\"\n",
    "    \n",
    "    winner_part, loser_part = parts[0].strip(), parts[1].strip()\n",
    "    \n",
    "    def extract_seed(text):\n",
    "        match = re.search(r'\\((\\d+)\\)', text)\n",
    "        return match.group(1) if match else \"\"\n",
    "    \n",
    "    def extract_name(text):\n",
    "        text = re.sub(r'\\(\\d+\\)', '', text)\n",
    "        text = re.sub(r'\\[.*?\\]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    winner_seed = extract_seed(winner_part)\n",
    "    loser_seed = extract_seed(loser_part)\n",
    "    winner_name = extract_name(winner_part)\n",
    "    loser_name = extract_name(loser_part)\n",
    "    \n",
    "    player_last_name = player_name.split()[-1].lower()\n",
    "    winner_last_name = winner_name.split()[-1].lower() if winner_name else \"\"\n",
    "    player_won = player_last_name == winner_last_name\n",
    "    \n",
    "    return player_won, winner_name, loser_name, winner_seed, loser_seed\n",
    "\n",
    "def parse_bp_saved(bp_text):\n",
    "    \"\"\"Parse break points saved like '5/8' into (saved, faced).\"\"\"\n",
    "    try:\n",
    "        if '/' in bp_text:\n",
    "            parts = bp_text.split('/')\n",
    "            return parts[0].strip(), parts[1].strip()\n",
    "    except (ValueError, IndexError):\n",
    "        pass\n",
    "    return \"\", \"\"\n",
    "\n",
    "print(\"✓ Parser functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_player_lookup(tour):\n",
    "    \"\"\"Load player info for ID lookup.\"\"\"\n",
    "    players = {}\n",
    "    player_file = DATA_DIR / f\"tennis_{tour}\" / f\"{tour}_players.csv\"\n",
    "    \n",
    "    if not player_file.exists():\n",
    "        return players\n",
    "    \n",
    "    with open(player_file, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            name = f\"{row.get('name_first', '')} {row.get('name_last', '')}\".lower().strip()\n",
    "            players[name] = row\n",
    "            players[row.get('name_last', '').lower()] = row\n",
    "    \n",
    "    return players\n",
    "\n",
    "print(\"✓ Player lookup function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player_matches(page, player_id, url_name, full_name, tour, player_lookup, min_year):\n",
    "    \"\"\"Scrape recent matches for a single player.\"\"\"\n",
    "    matches = []\n",
    "    prefix = \"w\" if tour == \"wta\" else \"\"\n",
    "    url = f\"https://www.tennisabstract.com/cgi-bin/{prefix}player.cgi?p={url_name}\"\n",
    "    \n",
    "    try:\n",
    "        page.goto(url, timeout=60000, wait_until=\"domcontentloaded\")\n",
    "        page.wait_for_timeout(3000)\n",
    "        \n",
    "        table = page.query_selector(\"#recent-results\")\n",
    "        if not table:\n",
    "            return matches, \"No table found\"\n",
    "        \n",
    "        rows = table.query_selector_all(\"tr\")\n",
    "        \n",
    "        for row in rows[1:]:\n",
    "            cells = row.query_selector_all(\"td\")\n",
    "            if len(cells) < 8:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                cell_texts = [c.inner_text().strip() for c in cells]\n",
    "                date_text = cell_texts[0]\n",
    "                tourney_date, year = parse_date(date_text)\n",
    "                \n",
    "                if year < min_year:\n",
    "                    continue\n",
    "                \n",
    "                match = {col: \"\" for col in get_match_columns()}\n",
    "                match[\"tourney_date\"] = tourney_date\n",
    "                match[\"tourney_name\"] = cell_texts[1]\n",
    "                match[\"surface\"] = parse_surface(cell_texts[2])\n",
    "                match[\"round\"] = parse_round(cell_texts[3])\n",
    "                \n",
    "                player_rank = cell_texts[4]\n",
    "                opponent_rank = cell_texts[5]\n",
    "                \n",
    "                result_text = cell_texts[6]\n",
    "                player_won, winner_name, loser_name, winner_seed, loser_seed = parse_result_cell(\n",
    "                    result_text, full_name\n",
    "                )\n",
    "                \n",
    "                match[\"score\"] = cell_texts[7]\n",
    "                \n",
    "                clean_name = re.sub(r'[^a-zA-Z0-9]', '', match[\"tourney_name\"])\n",
    "                match[\"tourney_id\"] = f\"{year}-{clean_name[:20]}\"\n",
    "                \n",
    "                if player_won:\n",
    "                    match[\"winner_id\"] = str(player_id)\n",
    "                    match[\"winner_name\"] = full_name\n",
    "                    match[\"winner_seed\"] = winner_seed\n",
    "                    match[\"winner_rank\"] = player_rank\n",
    "                    match[\"loser_name\"] = loser_name or winner_name\n",
    "                    match[\"loser_seed\"] = loser_seed\n",
    "                    match[\"loser_rank\"] = opponent_rank\n",
    "                else:\n",
    "                    match[\"loser_id\"] = str(player_id)\n",
    "                    match[\"loser_name\"] = full_name\n",
    "                    match[\"loser_seed\"] = loser_seed\n",
    "                    match[\"loser_rank\"] = player_rank\n",
    "                    match[\"winner_name\"] = winner_name or loser_name\n",
    "                    match[\"winner_seed\"] = winner_seed\n",
    "                    match[\"winner_rank\"] = opponent_rank\n",
    "                \n",
    "                # Lookup opponent ID\n",
    "                opponent_name = match[\"loser_name\"] if player_won else match[\"winner_name\"]\n",
    "                opponent_info = player_lookup.get(opponent_name.lower(), {})\n",
    "                if not opponent_info:\n",
    "                    opponent_last = opponent_name.split()[-1].lower() if opponent_name else \"\"\n",
    "                    opponent_info = player_lookup.get(opponent_last, {})\n",
    "                \n",
    "                if opponent_info:\n",
    "                    if player_won:\n",
    "                        match[\"loser_id\"] = opponent_info.get('player_id', '')\n",
    "                    else:\n",
    "                        match[\"winner_id\"] = opponent_info.get('player_id', '')\n",
    "                \n",
    "                # Parse time and BP stats\n",
    "                if len(cell_texts) > 15:\n",
    "                    match[\"minutes\"] = parse_time_to_minutes(cell_texts[15])\n",
    "                    if len(cell_texts) > 14:\n",
    "                        bp_saved, bp_faced = parse_bp_saved(cell_texts[14])\n",
    "                        if player_won:\n",
    "                            match[\"w_bpSaved\"] = bp_saved\n",
    "                            match[\"w_bpFaced\"] = bp_faced\n",
    "                        else:\n",
    "                            match[\"l_bpSaved\"] = bp_saved\n",
    "                            match[\"l_bpFaced\"] = bp_faced\n",
    "                \n",
    "                matches.append(match)\n",
    "            \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        return matches, None\n",
    "    \n",
    "    except PlaywrightTimeout:\n",
    "        return matches, \"Timeout\"\n",
    "    except Exception as e:\n",
    "        return matches, str(e)\n",
    "\n",
    "print(\"✓ Scraper function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_matches(matches):\n",
    "    \"\"\"Remove duplicate matches.\"\"\"\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    \n",
    "    for match in matches:\n",
    "        names = sorted([match.get('winner_name', ''), match.get('loser_name', '')])\n",
    "        key = (\n",
    "            match.get('tourney_date', ''),\n",
    "            match.get('tourney_name', ''),\n",
    "            match.get('round', ''),\n",
    "            names[0],\n",
    "            names[1],\n",
    "        )\n",
    "        \n",
    "        if key not in seen and any(key):\n",
    "            seen.add(key)\n",
    "            unique.append(match)\n",
    "    \n",
    "    return unique\n",
    "\n",
    "def merge_with_existing(new_matches, existing_file):\n",
    "    \"\"\"Merge new matches with existing data.\"\"\"\n",
    "    if not existing_file.exists():\n",
    "        return new_matches\n",
    "    \n",
    "    existing = pd.read_csv(existing_file)\n",
    "    existing_records = existing.to_dict('records')\n",
    "    \n",
    "    existing_keys = set()\n",
    "    for match in existing_records:\n",
    "        names = sorted([str(match.get('winner_name', '')), str(match.get('loser_name', ''))])\n",
    "        key = (\n",
    "            str(match.get('tourney_date', '')),\n",
    "            str(match.get('tourney_name', '')),\n",
    "            str(match.get('round', '')),\n",
    "            names[0],\n",
    "            names[1],\n",
    "        )\n",
    "        existing_keys.add(key)\n",
    "    \n",
    "    truly_new = []\n",
    "    for match in new_matches:\n",
    "        names = sorted([str(match.get('winner_name', '')), str(match.get('loser_name', ''))])\n",
    "        key = (\n",
    "            str(match.get('tourney_date', '')),\n",
    "            str(match.get('tourney_name', '')),\n",
    "            str(match.get('round', '')),\n",
    "            names[0],\n",
    "            names[1],\n",
    "        )\n",
    "        if key not in existing_keys:\n",
    "            truly_new.append(match)\n",
    "    \n",
    "    all_matches = existing_records + truly_new\n",
    "    all_matches.sort(key=lambda x: str(x.get('tourney_date', '')))\n",
    "    \n",
    "    return all_matches, len(truly_new)\n",
    "\n",
    "def save_matches(matches, output_file):\n",
    "    \"\"\"Save matches to CSV.\"\"\"\n",
    "    if not matches:\n",
    "        return\n",
    "    \n",
    "    columns = get_match_columns()\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "        for match in matches:\n",
    "            row = {col: match.get(col, '') for col in columns}\n",
    "            writer.writerow(row)\n",
    "\n",
    "print(\"✓ Utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the Scraper\n",
    "\n",
    "Execute this cell to start scraping based on your configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scraper(tour, min_year, max_players, merge_with_existing_flag, rate_limit):\n",
    "    \"\"\"Main scraper function with progress display.\"\"\"\n",
    "    \n",
    "    results = {\"atp\": [], \"wta\": []}\n",
    "    \n",
    "    tours_to_scrape = [\"atp\", \"wta\"] if tour == \"both\" else [tour]\n",
    "    \n",
    "    for current_tour in tours_to_scrape:\n",
    "        players = ATP_TOP_25 if current_tour == \"atp\" else WTA_TOP_25\n",
    "        players_to_scrape = players[:max_players] if max_players else players\n",
    "        player_lookup = load_player_lookup(current_tour)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Scraping {current_tour.upper()} - {len(players_to_scrape)} players\")\n",
    "        print(f\"Looking for matches from {min_year} onwards\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        all_matches = []\n",
    "        \n",
    "        with sync_playwright() as p:\n",
    "            browser = p.chromium.launch(headless=True)\n",
    "            context = browser.new_context(\n",
    "                user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "            )\n",
    "            page = context.new_page()\n",
    "            \n",
    "            for i, (player_id, url_name, full_name) in enumerate(players_to_scrape):\n",
    "                print(f\"[{i+1}/{len(players_to_scrape)}] {full_name}...\", end=\" \")\n",
    "                \n",
    "                matches, error = scrape_player_matches(\n",
    "                    page, player_id, url_name, full_name,\n",
    "                    current_tour, player_lookup, min_year\n",
    "                )\n",
    "                \n",
    "                if error:\n",
    "                    print(f\"⚠️ {error}\")\n",
    "                else:\n",
    "                    print(f\"✓ {len(matches)} matches\")\n",
    "                \n",
    "                all_matches.extend(matches)\n",
    "                time.sleep(rate_limit)\n",
    "            \n",
    "            browser.close()\n",
    "        \n",
    "        # Deduplicate\n",
    "        all_matches = deduplicate_matches(all_matches)\n",
    "        print(f\"\\n→ Total unique matches: {len(all_matches)}\")\n",
    "        \n",
    "        # Save scraped data\n",
    "        scraped_file = OUTPUT_DIR / current_tour / f\"{current_tour}_top25_matches_scraped.csv\"\n",
    "        save_matches(all_matches, scraped_file)\n",
    "        print(f\"→ Saved to: {scraped_file}\")\n",
    "        \n",
    "        # Merge with existing\n",
    "        if merge_with_existing_flag and all_matches:\n",
    "            existing_file = OUTPUT_DIR / current_tour / f\"{current_tour}_top25_matches.csv\"\n",
    "            if existing_file.exists():\n",
    "                merged, new_count = merge_with_existing(all_matches, existing_file)\n",
    "                save_matches(merged, existing_file)\n",
    "                print(f\"→ Merged {new_count} new matches into {existing_file}\")\n",
    "                print(f\"→ Total matches in merged file: {len(merged)}\")\n",
    "        \n",
    "        results[current_tour] = all_matches\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the scraper\n",
    "scraped_data = run_scraper(\n",
    "    tour=TOUR,\n",
    "    min_year=MIN_YEAR,\n",
    "    max_players=MAX_PLAYERS,\n",
    "    merge_with_existing_flag=MERGE_WITH_EXISTING,\n",
    "    rate_limit=RATE_LIMIT_SECONDS\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Scraping Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display scraped data\n",
    "for tour in [\"atp\", \"wta\"]:\n",
    "    scraped_file = OUTPUT_DIR / tour / f\"{tour}_top25_matches_scraped.csv\"\n",
    "    if scraped_file.exists():\n",
    "        df = pd.read_csv(scraped_file)\n",
    "        print(f\"\\n{tour.upper()} Scraped Matches: {len(df)}\")\n",
    "        print(f\"Columns: {len(df.columns)}\")\n",
    "        \n",
    "        if len(df) > 0:\n",
    "            display(df[[\"tourney_date\", \"tourney_name\", \"surface\", \"round\", \n",
    "                       \"winner_name\", \"loser_name\", \"score\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "for tour in [\"atp\", \"wta\"]:\n",
    "    merged_file = OUTPUT_DIR / tour / f\"{tour}_top25_matches.csv\"\n",
    "    if merged_file.exists():\n",
    "        df = pd.read_csv(merged_file)\n",
    "        df['tourney_date'] = pd.to_datetime(df['tourney_date'], format='%Y%m%d', errors='coerce')\n",
    "        \n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"{tour.upper()} Full Dataset Statistics\")\n",
    "        print(f\"{'='*40}\")\n",
    "        print(f\"Total matches: {len(df):,}\")\n",
    "        print(f\"Date range: {df['tourney_date'].min().date()} to {df['tourney_date'].max().date()}\")\n",
    "        print(f\"\\nMatches by year (recent):\")\n",
    "        print(df.groupby(df['tourney_date'].dt.year).size().tail(5))\n",
    "        print(f\"\\nTop tournaments:\")\n",
    "        print(df['tourney_name'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Single Player Scrape\n",
    "\n",
    "Scrape a specific player by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_single_player(player_name, tour=\"atp\", min_year=2025):\n",
    "    \"\"\"Scrape matches for a single player by name.\"\"\"\n",
    "    players = ATP_TOP_25 if tour == \"atp\" else WTA_TOP_25\n",
    "    \n",
    "    # Find player\n",
    "    player = None\n",
    "    for p in players:\n",
    "        if player_name.lower() in p[2].lower():\n",
    "            player = p\n",
    "            break\n",
    "    \n",
    "    if not player:\n",
    "        print(f\"Player '{player_name}' not found in {tour.upper()} Top 25\")\n",
    "        return None\n",
    "    \n",
    "    player_id, url_name, full_name = player\n",
    "    player_lookup = load_player_lookup(tour)\n",
    "    \n",
    "    print(f\"Scraping {full_name}...\")\n",
    "    \n",
    "    with sync_playwright() as p:\n",
    "        browser = p.chromium.launch(headless=True)\n",
    "        context = browser.new_context(\n",
    "            user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "        )\n",
    "        page = context.new_page()\n",
    "        \n",
    "        matches, error = scrape_player_matches(\n",
    "            page, player_id, url_name, full_name,\n",
    "            tour, player_lookup, min_year\n",
    "        )\n",
    "        \n",
    "        browser.close()\n",
    "    \n",
    "    if error:\n",
    "        print(f\"Error: {error}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(matches)\n",
    "    print(f\"Found {len(df)} matches from {min_year}+\")\n",
    "    return df\n",
    "\n",
    "# Example: Scrape Sinner's recent matches\n",
    "# sinner_matches = scrape_single_player(\"Sinner\", tour=\"atp\", min_year=2025)\n",
    "# display(sinner_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run to scrape a specific player:\n",
    "\n",
    "# sinner_matches = scrape_single_player(\"Sinner\", tour=\"atp\", min_year=2025)\n",
    "# if sinner_matches is not None:\n",
    "#     display(sinner_matches[[\"tourney_date\", \"tourney_name\", \"round\", \"winner_name\", \"loser_name\", \"score\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
